{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 01. Poetry generation\n",
    "\n",
    "Let's try to generate some poetry using RNNs. \n",
    "\n",
    "You have several choices here: \n",
    "\n",
    "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
    "\n",
    "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
    "\n",
    "* Some other text source, if it will be approved by the course staff.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
    "\n",
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "# Your great code here\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "    return result\n",
    "\n",
    "text = concatenate_list_data(text)\n",
    "text = text.lower()\n",
    "len(text)\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: \"Евгений Онегин\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(len(w) for w in words)\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title(\"Sequence length distribution\")\n",
    "plt.hist(list(map(len, words)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = concatenate_list_data(text)\n",
    "out = text.lower()\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100225"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = sorted(set(out))\n",
    "tokens\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {}\n",
    "idx_to_token = {}\n",
    "for idx, token in enumerate(tokens):\n",
    "    token_to_idx[token] = idx\n",
    "    idx_to_token[idx] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(tokens)\n",
    "assert len(tokens) == len(token_to_idx), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_idx[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder(inputstring):\n",
    "    integer_encoded = [token_to_idx[char] for char in example]\n",
    "    #print(integer_encoded)\n",
    "\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(tokens))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded[0].index(1))\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotdecoder(inputmatrix):\n",
    "    outputstring = []\n",
    "    for encodedletter in range(len(inputmatrix)):\n",
    "        letter = idx_to_token[np.argmax(inputmatrix[encodedletter])]\n",
    "        outputstring.append(letter)\n",
    "    outputstring = ' '.join(outputstring)\n",
    "    return outputstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k i t i n g   m a k e s   y o u   a   b o s s'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'kiting makes you a boss'\n",
    "onehotex = onehotencoder(example)\n",
    "#print(onehotex)\n",
    "\n",
    "IM = onehotex\n",
    "example_return = onehotdecoder(IM)\n",
    "example_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m o t o r c y c l i n g   m a k e s   y o u   a   n o m a d'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'motorcycling makes you a nomad'\n",
    "onehotex = onehotencoder(example)\n",
    "#print(onehotex)\n",
    "\n",
    "IM = onehotex\n",
    "example_return = onehotdecoder(IM)\n",
    "example_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(words, max_len=None, pad=token_to_idx[\" \"], dtype=\"int32\", batch_first=True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "\n",
    "    max_len = max_len or max(map(len, words))\n",
    "    words_ix = np.zeros([len(words), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        line_ix = [token_to_idx[c] for c in words[i]]\n",
    "        words_ix[i, :len(line_ix)] = line_ix\n",
    "\n",
    "    if not batch_first:  # convert [batch, time] into [time, batch]\n",
    "        words_ix = np.transpose(names_ix)\n",
    "\n",
    "    return words_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 19, 16, 16,  8,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [30, 16, 16, 20, 25, 18,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [26, 17,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [30, 20, 14, 22, 23, 36,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [24, 20, 25, 15,  8,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [20, 25,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [12, 25, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 19, 20, 25, 18, 30,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [33, 12, 20, 25, 23, 36,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [24, 36,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [30, 23, 12, 20, 25,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [19, 26, 24, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [36, 26, 32,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [17, 29, 12, 24, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [14, 35, 23, 20, 20,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [24, 16, 25,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [24, 26, 29, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 34, 20, 14, 16,  6,  7,  7, 20, 25,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [14, 35, 33, 20, 20,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 19, 12, 31,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 20, 24, 16, 30,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [17, 12, 24, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [26, 25,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 19, 16, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [34, 29, 26, 32, 18, 19, 31,  6,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 29, 20, 24, 24,  3, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 20, 24, 16,  3, 30,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [31, 16, 25, 12, 25, 31, 30,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [30, 27, 29, 20, 25, 18,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [20,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [34, 19, 16, 29, 16,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [24, 32, 31, 16,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "sample(words, 32)\n",
    "to_matrix(sample(words, 32), max_len=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "\n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        # batch, seq leng, emb dim\n",
    "        x_emb = self.embedding(x)\n",
    "\n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)  # YOUR CODE HERE\n",
    "        h_next = self.rnn_update(x_and_h)  # YOUR CODE HERE\n",
    "\n",
    "        h_next = torch.tanh(h_next)  # YOUR CODE HERE\n",
    "\n",
    "        assert h_next.size() == h_prev.size()\n",
    "\n",
    "        # compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)  # YOUR CODE\n",
    "\n",
    "        return h_next, logits\n",
    "\n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN loop\n",
    "\n",
    "Once we've defined a single RNN step, we can apply it in a loop to get predictions on each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0, 1):\n",
    "        hid_state, logits = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(F.log_softmax(logits, -1))\n",
    "\n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(words[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "assert torch.max(logp_seq).data.numpy() <= 0\n",
    "assert tuple(logp_seq.size()) == batch_ix.shape + (num_tokens,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood and gradients\n",
    "\n",
    "We can now train our neural network to minimize crossentropy (maximize log-likelihood) with the actual next tokens.\n",
    "\n",
    "To do so in a vectorized manner, we take `batch_ix[:, 1:]` - a matrix of token ids shifted i step to the left so i-th element is acutally the \"next token\" for i-th prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :-1]\n",
    "actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "# .contiguous() method checks that tensor is stored in the memory correctly to\n",
    "# get its view of desired shape.\n",
    "\n",
    "loss = criterion(\n",
    "    predictions_logp.contiguous().view(-1, num_tokens), actual_next_tokens.contiguous().view(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in char_rnn.parameters():\n",
    "    assert (\n",
    "        w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0\n",
    "    ), \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (\n",
    "        w.size(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training loop\n",
    "\n",
    "We train our char-rnn exactly the same way we train any deep learning model: by minibatch sgd.\n",
    "\n",
    "The only difference is that this time we sample strings, not images or sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAziElEQVR4nO3dd3gc5bn38e+96r33LttyxwW54IZpwRA6JIEktISQEJJAkpNzOOFNITkkITkhBQjGSWgJxZxQQjHVGNvgKstylVwkS1bvvZfn/WNXa1mWLNmWtNLu/bkuXd6dHc/eml395plnnpkRYwxKKaUmPoujC1BKKTUyNNCVUspJaKArpZST0EBXSiknoYGulFJOwt1RbxweHm6Sk5Md9fZKKTUh7dq1q8oYEzHQaw4L9OTkZDIyMhz19kopNSGJSMFgr2mXi1JKOQkNdKWUchIa6Eop5SQc1oeulFIjobOzk6KiItra2hxdyojy9vYmPj4eDw+PYf8fDXSl1IRWVFREQEAAycnJiIijyxkRxhiqq6spKioiJSVl2P9Pu1yUUhNaW1sbYWFhThPmACJCWFjYGe91aKArpSY8ZwrzXmfzO024QD9U1shv3s2hoa3T0aUopdS4MuEC/XhNC6s35pJb0eToUpRSCgB/f39HlwBMwEBPjfAD4FhVs4MrUUqp8WXCBXpCiC9uFiGvUgNdKTW+GGP40Y9+xKxZs5g9ezZr164FoLS0lBUrVjB37lxmzZrF5s2b6e7u5o477rDP+4c//OGc33/CDVv0dLeQEOKjLXSl1CkeeusAB0saRnSZM2ID+dnVM4c172uvvUZWVhZ79uyhqqqKBQsWsGLFCl588UUuv/xyHnzwQbq7u2lpaSErK4vi4mL2798PQF1d3TnXOuFa6ACpEf7kaaArpcaZTz/9lFtuuQU3NzeioqK48MIL2blzJwsWLOCZZ57h5z//Ofv27SMgIIDU1FTy8vL47ne/y3vvvUdgYOA5v/+Ea6EDpIT7sTW3mp4eg8XifMOVlFJnZ7gt6dFijBlw+ooVK9i0aRPvvPMOt956Kz/60Y+47bbb2LNnD++//z5PPPEEr7zyCk8//fQ5vf+EbKGnhPvR2tlNWYNzneqrlJrYVqxYwdq1a+nu7qayspJNmzaxcOFCCgoKiIyM5Bvf+AZf//rXyczMpKqqip6eHm688UZ++ctfkpmZec7vPyFb6KnhJ0a6xAb7OLgapZSyuv7669m6dStz5sxBRPjtb39LdHQ0zz33HL/73e/w8PDA39+f559/nuLiYu688056enoA+PWvf33O7y+D7SKMtvT0dHO2N7goq29j8a/X88vrZnHr4qQRrkwpNZFkZ2czffp0R5cxKgb63URklzEmfaD5J2SXS1SgFz4ebhzToYtKKWU3IQNdREiN8CO3Us8WVUqpXhMy0AHSogI4Ut7o6DKUUuOAo7qOR9PZ/E4TOtBL6tv0Il1KuThvb2+qq6udKtR7r4fu7e19Rv9vQo5yAUiLsl4M50h5I+cnhTq4GqWUo8THx1NUVERlZaWjSxlRvXcsOhMTONADADhU1qSBrpQL8/DwOKO7+jizIbtcRMRbRHaIyB4ROSAiDw0wj4jIn0XkqIjsFZH5o1PuCXHBPvh5unFY+9GVUgoYXgu9HbjYGNMkIh7ApyLyrjFmW595rgCm2H4WAU/a/h01FoswJSpAA10ppWyGbKEbq97xgR62n/5HH64FnrfNuw0IFpGYkS31VGlR/hroSillM6xRLiLiJiJZQAXwoTFme79Z4oDCPs+LbNP6L+duEckQkYyROICRFhVAVVMHVU3t57wspZSa6IYV6MaYbmPMXCAeWCgis/rNMtAlD08ZQ2SMWWOMSTfGpEdERJxxsf1NsR0Y1dvRKaXUGY5DN8bUAZ8Aq/q9VAQk9HkeD5ScS2HDkRBivTBXUW3raL+VUkqNe8MZ5RIhIsG2xz7ApUBOv9neBG6zjXZZDNQbY0pHutj+eq+0WFynga6UUsMZ5RIDPCciblg3AK8YY94WkW8BGGNWA+uAK4GjQAtw5yjVexJvDzciArwo1ha6UkoNHejGmL3AvAGmr+7z2AD3jmxpwxMX7KMtdKWUYgJfy6VXXIgGulJKgRMEenywD8W1rfT0OM+FeZRS6mxM+ECPC/Gho7tHx6IrpVzehA/0+N6hi9rtopRycRM+0OOCfQF0pItSyuVN/EDXk4uUUgpwgkD393InyMeD4roWR5eilFIONeEDHaxj0bWFrpRydU4R6CkRfuRVNju6DKWUciinCPSpUQEcr2mhub3L0aUopZTDOEegR1svo3tEL6OrlHJhzhHo9htGNzi4EqWUchynCPTEUF98PNzIKdPb0SmlXJdTBLrFInp/UaWUy3OKQAfr/UUPaQtdKeXCnCbQp0brDaOVUq7NqQId4LC20pVSLsppAj0l3A+A/Gq9BIBSyjU5TaDHBPng4SYU1OgZo0op1+Q0ge5mERJCfDmuLXSllItymkAHSAzzpUADXSnlopwq0JNCfSmsacEYvb+oUsr1OFWgJ4b50djeRW1Lp6NLUUqpMedcgR5qvR1dQbUeGFVKuR6nCvSkMGugH6/RfnSllOsZMtBFJEFENohItogcEJH7BphnpYjUi0iW7eeno1Pu6Z1ooWugK6Vcj/sw5ukCfmiMyRSRAGCXiHxojDnYb77NxpirRr7E4fP2cCMq0EsDXSnlkoZsoRtjSo0xmbbHjUA2EDfahZ2tpFA/CrXLRSnlgs6oD11EkoF5wPYBXr5ARPaIyLsiMnOQ/3+3iGSISEZlZeWZVzsMiWG+eraoUsolDTvQRcQfeBW43xjT/9ZAmUCSMWYO8BjwxkDLMMasMcakG2PSIyIizrLk00sM9aW8oZ22zu5RWb5SSo1Xwwp0EfHAGuYvGGNe6/+6MabBGNNke7wO8BCR8BGtdJh0pItSylUNZ5SLAH8Hso0xjw4yT7RtPkRkoW251SNZ6HDpSBellKsaziiXpcCtwD4RybJN+zGQCGCMWQ3cBNwjIl1AK3CzcdD590lh1svoagtdKeVqhgx0Y8yngAwxz+PA4yNV1LkI8fUgwMud43q2qFLKxTjVmaIAImIb6aItdKWUa3G6QAfrgVG9LrpSytU4ZaAnhPpSWNtCd49eRlcp5TqcMtCTQv3o7DaUNbQ5uhSllBozzhnoYXoZXaWU63HKQE8IsQZ6UU2rgytRSqmx45SBHhXkBUBpvXa5KKVch1MGupe7G+H+XpTWawtdKeU6nDLQAWKCvLWFrpRyKU4e6NpCV0q5DucO9DptoSulXIfzBnqwD43tXTS2dTq6FKWUGhPOG+hB3gCUaT+6UspFOHGg+wA6dFEp5TqcONCtLXQ9MKqUchVOG+hRgd6IaAtdKeU6nDbQPd0t1pOLdKSLUspFOG2gg7XbpUS7XJRSLsLpA127XJRSrsKpAz022IeSulYcdL9qpZQaU04d6PEhvrR0dFPboicXKaWcn1MHekKIdSx6Ua3eX1Qp5fycOtDje290UasHRpVSzs+pAz3O1kIvrNEWulLK+Tl1oAf5eBDo7a4tdKWUSxgy0EUkQUQ2iEi2iBwQkfsGmEdE5M8iclRE9orI/NEp98zFh/hqH7pSyiUMp4XeBfzQGDMdWAzcKyIz+s1zBTDF9nM38OSIVnkOEkJ9tIWulHIJQwa6MabUGJNpe9wIZANx/Wa7FnjeWG0DgkUkZsSrPQvWFrqORVdKOb8z6kMXkWRgHrC930txQGGf50WcGvqIyN0ikiEiGZWVlWdY6tmJD/GhtbOb6uaOMXk/pZRylGEHuoj4A68C9xtjGvq/PMB/OaVJbIxZY4xJN8akR0REnFmlZ0mHLiqlXMWwAl1EPLCG+QvGmNcGmKUISOjzPB4oOffyzl1CqA5dVEq5huGMchHg70C2MebRQWZ7E7jNNtplMVBvjCkdwTrPWmKotYVeUN3s4EqUUmp0uQ9jnqXArcA+EcmyTfsxkAhgjFkNrAOuBI4CLcCdI17pWfL1dCcu2IcjFU2OLkUppUbVkIFujPmUgfvI+85jgHtHqqiRNiXKnyPlGuhKKefm1GeK9poS6U9uZRPdPTp0USnlvFwk0ANo7+rRM0aVUk7NJQJ9cpQ/gHa7KKWcmmsEeqQt0PXAqFLKiblEoAd6exAT5M2RikZHl6KUUqPGJQIdrK30o9pCV0o5MZcJ9EkR/uRWNOlFupRSTstlAj0+xIfmjm7qW/WG0Uop5+RSgQ5QXKcX6VJKOSeXCfTYYFug61UXlVJOymUCPS5YW+hKKefmMoEe6ueJt4eFEg10pZSTcplAFxFig320ha6UclouE+hg7XYprmtzdBlKKTUqXC/Q9aCoUspJuVygVzW109bZ7ehSlFJqxLlUoPcOXSyt124XpZTzcalAjwvRsehKKeflWoFua6Hr0EWllDNyqUCPDvLG083C0Uq96qJSyvm4VKB7uFmYHhPAvqJ6R5eilFIjzqUCHWBWXBD7S+rp0RtGK6WcjMsF+nnxQTS2dVFQozeMVko5F5cL9NlxwQDsK9ZuF6WUc3G5QJ8S5Y+nu4V9RXWOLkUppUbUkIEuIk+LSIWI7B/k9ZUiUi8iWbafn458mSPHw83CjJhA9uqBUaWUkxlOC/1ZYNUQ82w2xsy1/fzi3MsaXbPjgjhQ0qD3F1VKOZUhA90YswmoGYNaxkxKuB9N7V3Utej9RZVSzmOk+tAvEJE9IvKuiMwcbCYRuVtEMkQko7KycoTe+szFBHkDUFKvZ4wqpZzHSAR6JpBkjJkDPAa8MdiMxpg1xph0Y0x6RETECLz12Ym2BXqZXqRLKeVEzjnQjTENxpgm2+N1gIeIhJ9zZaMoJkivuqiUcj7nHOgiEi0iYnu80LbM6nNd7miKCPDCzSLaQldKORX3oWYQkZeAlUC4iBQBPwM8AIwxq4GbgHtEpAtoBW4243z4iJtFiArw0ha6UsqpDBnoxphbhnj9ceDxEatojEQHeVPWoAdFlVLOw+XOFO0VE+SjLXSllFNx2UCPDvKmtK5NTy5SSjkNlw30mCBvWju7aWjtcnQpSik1Ilw20HvHopdqP7pSykm4bKDrWHSllLNx4UDXs0WVUs7FZQM90nZy0bGqZkeXopRSI8JlA93dzcLSyeG8taeEbr2/qFLKCbhsoAPcvCCB0vo2Nh9x3JUflVJqpLh0oF86PYpQP0/W7ix0dClKKXXOXDrQPd0t3DAvjg8PltPUruPRlVITm0sHOsAFk8Lo6jHklDY4uhSllDonLh/oM2ODADhQooGulJrYXD7QowK9CPXz5KAGulJqgnP5QBcRZsQEclC7XJRSE5zLBzrAzNhADpU10tnd4+hSlFLqrGmgAzNiA+no7iG3ssnRpSil1FnTQMfaQge0H10pNaFpoAMp4f54e1jYVVDr6FKUUuqsaaBjvWn05TOjeTOrRE8wUkpNWBroNncsSaaxvYvXMoscXYpSSp0VDXSbeYkhzIkP4tkt+fTo1ReVUhOQBnofNy9MJK+yWUe7KKUmJA30PubEBwOQXdbo2EKUUuosDBnoIvK0iFSIyP5BXhcR+bOIHBWRvSIyf+TLHBuTI/1xt4heqEspNSENp4X+LLDqNK9fAUyx/dwNPHnuZTmGp7uFyZH+ZGugK6UmoCED3RizCag5zSzXAs8bq21AsIjEjFSBY21adAA52uWilJqARqIPPQ7oe8ufItu0U4jI3SKSISIZlZXj87Zv02MCKa1vo66lw9GlKKXUGRmJQJcBpg047s8Ys8YYk26MSY+IiBiBtx5502KslwHILtVWulJqYhmJQC8CEvo8jwdKRmC5DjE9OgCAnDLtR1dKTSwjEehvArfZRrssBuqNMaUjsFyHiAjwIkxveKGUmoDch5pBRF4CVgLhIlIE/AzwADDGrAbWAVcCR4EW4M7RKnYsiAhzE4LJPK4X6lJKTSxDBrox5pYhXjfAvSNW0TiQnhzK+pwKqpvaCfP3cnQ5Sik1LHqm6AAWJIcA6OV0lVITigb6AGbHB+HpbiFDA10pNYFooA/Ay92NOfFB7Mw/3flUSik1vmigDyI9OZR9RfW0dnQ7uhSllBoWDfRBrJgSQVeP4R/b8h1dilJKDYsG+iAumBTGJdMi+eNHRyitb3V0OUopNSQN9NP4+TUz6e4xPPrBYUeXopRSQ9JAP42EUF8+f14M63Mq9LZ0SqlxTwN9CMunhFPT3MHB0ga251Wz5WiVo0tSSqkBDXmmqKtbOjkcgPf2l/HP7QW0dHTz5neWMi060MGVKaXUybSFPoTIAG+mRQfw1KZc6lo68XK38L2XdlPR0Obo0pRS6iQa6MOwIi2Czm7DkklhPP7l+eRWNrPkNx/z2Pojji5NKaXsNNCH4XMzonCzCN+7ZAoXpkWw/gcXsiA5lL9uzsMYQ1VTO7mVTY4uUynl4jTQhyE9OZSsn17G4tQwAJLD/bhmbiwNbV0cr2nh528e4Kt/2+7gKpVSrk4DfZgCvD1Oej47LgiAPUX1bMmtprS+jYpG7VdXSjmOBvpZSosKwNPNwuuZRdQ0W28o3Xsf0paOLlb+bgP/2lXkyBKHraOrx9ElKKVGgAb6WfJ0tzA9JoANhyrt03pvW7c+u4L86hb+8OFhurrHd1jmVzUz62fvk1VY5+hSlFLnSAP9HMyydbvEBnkTF+zDwVJroL+1pwQPN6G4rpV39p18e9VdBTWU1Y+frpns0gY6unvYmlvt6FKUUudIA/0cnBdvDfTFqWHMiA0ku7SBhrZOPjlcyVcWJTE50p/VG60jYQB6egy3P72T37yb7ciyT1JcZ73w2IGSegdXopQ6Vxro52BeovVWdUsnhzMjJpC8yiZezyymo6uHa+bGcveKVLJLG9h8xHq5gKLaVprau9iWV2MPeUcrqrUGem93kVJq4tJAPwdpUQG89Z1lXD8vjhmxgfQYeOitA0yPCWReQjDXzo0lKtCLpzblAnC43HrQtKyhjaLaVr75j4xzOjmpo6uHW9Zs48OD5We9jN4W+rHqZprbu856OUopx9NAP0ez44OwWIRZcUFYxNqv/s+vL0RE8HJ342tLU/jsaDX7iuo5ZAt0gL9tzuP9A+U8tSnvrIN0x7EatuZV8+t12XT3GA6XN9J0hssqrm3Fy92CMZBTpq10pSYyDfQREhfsw9vfXc7auy8gzN/LPv3LixLx83TjxR0FHC5vJCbImxBfD57fVoCbRWhq7+KNrOJTlmeMYXteNfWtnYO+50fZ1pZ5XlUz//XqXlb9cROrP8m1v56RX8NNT26hvmXwZRTXtbJ8ivUCZAfOsdvlwdf38c9tBee0DKVGS3N7F58dreKTQxW0dTrnrSU10EfQjNhAfDzdTpoW4O3ByqmRfHiwgpzSRqZFB7AgORRj4IZ5ccyMDeQfWwtO6VN/ccdxvrRmGwse/ognNhw95b2MMazPKWfl1AgmR/rzr11F9BjIKTuxF/D3T4+RUVDLCzsGDtmm9i7qWzs5PymUEF8Pez+6MeaMv/CFNS28sP04L24/PuS8HV09/PrdbL3A2RhoaOvU8wxsfrUum6/8bTt3PLNzwpwjcqY00MfA52ZGUdXUzqHyRtKiArhgkvUSAl9elMiti5PIKWtkW16Nff7yhjZ+sy6HBckhnBcXZL9mTF9HKpoorGnlshlR/OLamdx0fjzLJodzrMp6TZn6lk7WZ1cgAs9+lj/gH3Wx7YBoXIgPs+KC2Hi4kvyqZr701DZu+MuWM/od39pbAkB2WcNp9yrA2lX01MY8/s9J/6jGi54ewxV/3Mwj7+WMyfsdrWjivpd3j9vWb25lEzNiAvHzdONoxanXXnpiw1H2TPDzMYYV6CKySkQOichREXlggNdXiki9iGTZfn468qVOXCunRuJuEcB6IPWWhYm88s0LmJcYwnXz4gj392SN7cBpd4/hgVf30tHdw+9umsM1c2Opa+mkrF9rtvdA6CXTolgyKZz//cIcZscHcbymha7uHt7ZV0pHdw//8bmpVDS28+8BunWK61oAa3fR/ZemUd/ayaWPbmRHfg0HSxsoqm057e/V3tXND9ZmsWZTLm9mlRDg5Y4xkFlQe9r/l1Fg3XhtyR36ZiEdXT0crz59Hf0NVffZqmxs53sv7aa6qX3EltnV3cMXn9rKox8cGrFl9tpbXE9xXSvv7S8bk1FV7+4r5d9ZJWQeP/3n7yhFta2kRfmTFOZHQXXzSa8dq2rmd+8f4qUdQ+9hjmdDBrqIuAFPAFcAM4BbRGTGALNuNsbMtf38YoTrnNCCfDzsF/ZKiwrA28ONhSmhAHh7uHHHkmQ2HKokq7COh946wIZDlfy/q2aQHO7H9BjrjTSyS0/0b7d1dvPclnwWp4YSHeRtn54S7kdnt6GotpXXdxcxKcKPb6+cRFKYL+8fKDulrt4WenyID+cnhfDc1xYSG+zDN1ekArC9z15DL2MM976Qyc/fPMB//Wsvr+0u5lfrcsgpa+TeiyfjbhF25J/6/+DEJQZ22QI/I792yNbc81vzuej3n9hHCA1l85FKlj2ygU8OVQxr/qHklDVw5Z82U9nYzjt7S3hzT8mwupUG8pt3c045geulnYXsOFbD2/1OQOtVWt/Kit9uOGlY6Tt7S7n96R38el32aY+PbMixroPiulZyK5sHnW+kHLa1encfrxv19zpTXd09lNW3ERfiQ1KYLwU1J2/0Pzxo/fs4MkDLHazf3XX7SsfNcOPBDKeFvhA4aozJM8Z0AC8D145uWc7nC+nxxAX7MCXK/5TXvro4CV9PN6574jOe31rA3StSuXVxEgDTogOAE9eJAVi7s5CKxna+d8mUk5YzKcIPsAZmRkEtV8+JRcQ6AudwufWLeqyq2T5UsaiuFU83CxG2g7gLkkPZ9J8X8V+rphHs68G2PGv4tHV284XVW/joYDmHy5t4Z18pz27J542sEr53yRTuu2QKSWG+3HR+PLPigth57NRAf3dfKXMe+oCPc8rZfbyO+BAf2rt6eHtvKRf+bgPrswceerklt5ruHsPv+7Rg2zq77X9YR8obOVZ1IqweW2893vBRv+UZY9iWV01716kbkAMl9TS0DRyMG3IqOVjawPsHythqWx+v7Coc8h6zGfk13Pfybr6/NotDZY2U1bexemMuP359n/1yEHUtHTz6wSE83IS8ymaqmtp55L0c+96adTm1HK9p4bXME91TL2wvYPuxav66OY8/f3xi2Ksx5qSutU8OV5IQ6mN93GcDZ4zh3hcz+c9/7Tmne+U++Po++0YDrJ8FnNhgj5buHsOhsuFt4H/zbg73vphJeWM7XT2G+BBfksL8KKxpobvP7/7BAev35WhFE8YYfvHWQd7Ze2Ij+9aeEr79QibbB/hu91ff2mn/Gxtrwwn0OKCwz/Mi27T+LhCRPSLyrojMHGhBInK3iGSISEZlZeVAszita+fG8dkDF+Pt4XbKa8G+nvzxS3P5wWVp/PW2dB5YNc3+WoC3BwmhJy4rUN7QxpOf5LIwOZQLbK3+Xinh1o3F89sKMAYuTIsAIC0ygMLaFlo6uvjmPzL40lNbaWrvori2lZhgbyy27qBeFouwMDnU/uV9/0AZO/NreW5rPpuPWD+3Z+5cwG9vPI/vXzqF71+WxsYfXUS4vxcLU0LZW1R/Ust7f3E9338li9bObh54dR9N7V18c0UqFoH/fm0vBdUt/HVznn1+Ywxd3T309Bgy8mvw83Tj/QPl9v7NLz61lev+soXNRyq59onPuPyPm/jrpjze3VfKjvwafDzc2Hi48qTW1N8/PcbNa7bxlw3WsNyZX0NjWydtnd3c8JctPPLuiX7mvoHRu97XZ5ez/VgN4f5eFNa02jd2g/nT+iN8cKCct/eW8OyWY/ZuiGNVzby+u5im9i7uei6DhrYufna19c/lgwPl/HVTHo+tP2pff719ve8ftHabGGM4UNLA9fPi+dyMaP6dVUynbQPx/NYClvzmY1o6uqhqamdvUR1fPD+BSRF+bDx84u/ttcxi3tlbyisZRTy5Mbdv2VQ0tg2ri6u+tZMXth/nJ//eT2d3D13dPeTZ9gIyj9eec0u2vat70GU889kxVv1p05DDbI0xvL67iI8OllNg2+jHBfuQHOZLZ7ehxBa6lY3t7DpeS2SAF/WtneRWNvH0Z8d45L0c+wavdwTYUJ87wMPvHOT6Jz5zyI3lhxPoMsC0/pVmAknGmDnAY8AbAy3IGLPGGJNujEmPiIg4o0Kd3edmRvO9S6Zw2YyoUwJ2erT1sgJZhXVc9dinNLR18sCV0xA5eb5QP0+CfT3YU1hHkI8H58UHA5AW5Y8x1tbe4fImimpbuePpHby3v4xZsUED1rMoNYzjNS2U1LXa+xW35Fbz1t5SJkf6c9HUSL64IOGUGi5Mi6Cju4fVtqBo6+zmOy9mEubnxY8ut/bng/W4wnnxwXR2G+bEB7Etr8be0n7s46Nc8JuP2V1YR0NbF/+5ahpBPh4889kxiuta2VtUz57COm79+w5CfD1ZPjmch9dlc88LmYT7e/L9y6ZQWNPK7sI6frA2i2+/sItfrcvGIvD67mIOljTwhdVbWbMpj/3F9bR39fDu/jJ7y/mlHcdZ9adNHKtqtnd1fXK4krqWTn5wWRqB3u6szTjRximpa2XZIx+z3fbHXtfSwdbcau5cmsxFUyPZfKSKjPxavNwtzIwN5JdvH+TS328kq7COx2+ZxxfTE/Byt/Doh4fo6jE0tnfZj5H0BnphTSs5ZY0U1bZS39rJrLhAbpgfR1VTh30juy2vmqqmdt4/UMbH2RUYAxdNi2Tl1Ei2H6uhqb2LupYOHl6XzfzEYK6ZE8v/fnDopAOBP1i7hy//bduQgdwb+kW1rby6q4j86hY6untYmBJKXUsnebbPsq6lY9C9n8E0t3ex+FfreX7rqaOzenoM/7A1WF7LPPW4UF/Hqpopb2invauHTbazteNDfEgM87X+DrZul/XZ5RgDdy1PAax7wL2vf2q7KfzBUuulMbblVZNd2sDy3358Sj98r4yCWioa2+2NgbE0nEAvAhL6PI8HSvrOYIxpMMY02R6vAzxEJHzEqnRx02MCOVbVzF3P7cTbw8Ib9y5lvu2yA/2lhlu7XZZNDset90CsrdvmFVsILUgOIaOgloUpofz6xtkDLmdxqrWP/2dvHmBbXg1XzIqmu8ewp7DOPm59IEsnh3PDvDj+vP4Imw5X8tTGPPKrW3jkxvP4xvJU4oJ9iAzwIj7Eh28sT+WuZSn89bZ03CzCyzuPU1jTwuMbjlLZ2M6Dr+8DrBuJS6dHseFQJZttLc0fXzmNRSmhPPe1hfzt9nRevWcJv7p+Nk/dms7lM6MBuPOZnby1t4R9xfUsmxLBQ9fO4nhNC/ev3Q1YN1C9V5msae6w75F8ZPsDf/9AGXmVTcxNCKY33y6aFsEVs2L4OLvC3jJ+bks+RbWtvGDrW/8ou4KuHsOqWdEsnxJOUW0r7+wrYU5CML+4dibnxQczNyGYv96ezhWzY/B0tzA3IZiqpg7SovyJDfLmVVsXy9GKJubEByFibcH3thRnxgaxcmokoX6evLrLGmy9Q1Zf2VnE6o25TI0KYEZMINfMiaWjq4c1m/J45L0c6ls7efj62fzqhtkEeLnbN77VTe1sya2iqLb1lHMS/p1VzD3/3GXvsz9mC7OIAC8e33DUfi2gWxZaoyKzoJaGtk4+/+dPufC3G86o/3lbXjW1LZ0DHqDcfLSKguoWQnw9+HdW8UndJqcu50T3SG8feWywD8lh1r+RfNvv8O+sEpLCfLl6TiwAr2YW424RQnw9eHH7cYwx9i7PzON1PL7hKIU1rXyUfepxmqb2LnvDZNORSnp6znwI8LlwH8Y8O4EpIpICFAM3A1/uO4OIRAPlxhgjIguxbij08n0jZEZsIMZAc3s3L35jMWlRAYPOmxLuT+bxOlaknQjdpFBfPN0sfHCgHIvA325bwPZj1Vw4NQIv91O7gABmxARy94pU/rY5DzeL8NA1M9lXXE9RbSsrppx+7+qha2eSebyW257eAcDVc2JZZtsIPPnV+TS1dSEifP68GD5/XgwAF0+L5NnP8lmfXYFFrO9/sLSBcH8vksJ8uXR6JK9mWrsIwvw8+cbyVO5eMcn+nucnhXB+0omNXFKYLwXVLfzyuln24xFN7V08/M5BDpc3EeDlzp7COkJ8PYgM8KKpvYt39pVyflKIfbf6uS359Bi4c2ky//3aPiIDvIgJ8uHi6ZGszShkZ34NcxOCeWnHcUSsI49aOrp4b38ZsUHezI4Lst8YpbyhnRvmx3N+Uij/vGvRKetsga2L67p5cTS1dbF6Yy6l9a3kVTXxtWUpuLtZeHtvCZ3d0bhZhGnRAXi6W7jqvBjW7iyktrmD/OpmAr3d7X39a249H4tFmJMQzOfPi2H1xlw6unq4e0Wq/WD7Vxcn8eTGXPKrmtl+rJrefPzgYLn9aqJN7V089NZBapo7OF7Twgt3LbJ3Yfzimpnc80Imf/zoCCJw+cxoAr0P8M9tBXxyqJLS+lbSogL49guZzIkP4sdXTmdRv65CsO7J3f9yFt+8MJVNto12Tlkj2aUN9loB/rmtgDA/T35y1QzuX5vFhpwKogK9eezjI4T6efLg56fb1/nWvGoiAryob+kkt7KZiAAvvD3ciA70xtPdwvFq6x7otmPV3H9JGtGB3vh7uVPT3MHchGAWpoTy90+PkVVYR31rJyunRvDJoUp73/q2vGq+vizlpN/jQHE9xoCbRdh82Lpx/CSngk3/eRHubqM/SnzIdzDGdAHfAd4HsoFXjDEHRORbIvIt22w3AftFZA/wZ+BmM94PB08g8xKDCfH14Fc3zDptmIP1IKpFYHmf0HV3s5Aa4UdHdw/TogMJ8vXgczOjBw1zABHhx1dO5+3vLufZOxcQGejNNXNi8fM8MUJnMAHeHvz73mU8dM1Mrp4Ty0+umm5/7bz4YJZMPrWF/8trZ/H582LIr2rmuxdP4QeXpQHWvQkRYXlaBJ5uFgqqW7hgUtgpXT39fXvlJL55YSpfXZRon+bv5c6qmdF4ulv4ydUz6OoxrM+pID05hIunRfL+/jLbWYQ9pIT7UWq7zPG8hBB++LmpfOdi60HoZZPD8XSzsCGngtcyi2lo6+KHl6XR2tnNExuOsulIJZfPikZESA7zJT7EemDy/EH2qgBWzYpmcqQ/N8yL54b58fQYa9dTZ7dhSmQAX16YyJGKJl7ccZzJEf72YzErp0bQ3tXDC9ut3RDfuXgyAHMSgrlsRpR9+Q+smgbGeqnn+/ocTL9jaTIeFgu/e/8Qb+8tJSHUhwXJIXzQZ1TUM58eo6a5gx9dPpWcskb+/ukx8qtbiA70ZtWsaOYkBHOsqpnEUF98Pd156NqZHK2wHjy/Z+Uk3vruMh6+fhZVTR3c80ImLR1dVDS08YcPD3PDXz5jT2Ed6/aV8t6BMn79bg4bD1cyLzEYd4vwxu4T3SoVjW18nFPBTenxrJoVTYC3O3c9n8HVj3/K1rxqXsko5Io/beZAST3GGLbmVrNkUhhp0dZjS72fg8UiJIb6kl/dzBtZxRgD18+LQ0SYHGmdNz0phFsWJtLdY3jorYMA3L4kmd6vXXpSCNvzqk/ZQ9hXbN1TuXZuLDvya3hx+3FK6tsGHfk10obTQu/tRlnXb9rqPo8fBx4f2dJUr8gAbzJ/ctmQIQbwlcWJLEoNJTbY56TpaVEB5JQ1Mj8p+Izee0bsidbR/ZemcesFSfh5Df21CfL14PYlydy+JHlY7xMd5M2jX5zLw9fNxtvDem2Zm86P5ypbC97fy51FqaFsPlLF0gE2CP19aUHigNN/dvVM7l4xicQwX/77tX109xjmJgQzJz6YdftK+f7aPXi5W7j/0inc93IW/l7uxIf4nNQS87PV8s7eUprau5iXGMw9Kyfzj20FPLEhl5ggb+5cYp1fRFg+JZyXdhQyP2nwQJ8VF8RHP7jQ/nxOQrC9L3dypD8zYwN59MPDFNe1snLqiY31opQwPNyEZ7dY+5uvmBVDoLcH85NCTvq+JIT68uzXFhAZ4H3S5xcZ4M23L5rEHz+yjpa5e0UqEf5ePLwum2NVzXR197Bmcx6XzYji3osm88HBcrbn1dBtDMnhvogI9186hTuf2cmUSGtj4/p58SxMCWN9djk3L0jEw83CVxYlMTUqgJtsxy7e2F1MQU0Lnm4W/uedgwiCRawnnYE1PEN9PXkjq5jvX5aGt4cbb+y2drF84fwEvD3cePqOBewtqsfT3cI1c2I5WtHEd17M5Aurt7JkUjhVTe1ckBqGl7uF/cUNxIf42n/v5DBf9hbVc6CkgfSkEHu/+uRIf7IK60hPDiEl3I+lk8P47Gg1IrAwOZT0pBC8Pdy4cX4896/NIru0gVlxQVQ0tNHU3sW+4nqiA725YV48r2UWkxDqQ0VDOx8cKGfJJOv3tqKxDQxEBp4YcjxS9EzRCWI4YQ7g6+luPxja11RbP/pgfe/D4eluISbIZ+gZz4GPpxsigsUi/O8X5rByaqT9tStnx+BmEZYNI9AHE+LnyYzYQPy93O1dCnMTQliUGsaPr5xOa2c3i1LDWDk10t610f8gNcBFUyMpqW/D3c3Cn2+eh5tF+NaFk1g+JZw37l1qDwiA710yhSe/Mp9QP89h13nj/Dh7629ypD8ebha+daH1/ICZfQ5k+3m5My8xhKqmdvvG5+aFiQPuyS2ZFG5vgfZ1/6VpPPHl+cyKC+SLttavp5uFL6zewpfWbMPbw40Hr7TuZS1KCSWrsI6jFU32vuiVaRF8ZVEiN84/MfgtLtiH2y5IxtP9RMSkJ4eyODWUP350hMLaVl7+xmL+31Uz2Jlfy478Gr578RTCbOvowrQI7lqeSnlDO795NwdjDP/aVcS8xGD777AgOZSvL0vh1sVJBPl4cH5SCG/cu5QZMYFkFdZx+wVJXDcvzr6+4vo0cmbEBFJa30ZNcwffvuhE192s2EA83ITzk6x7oV9ZZO2uSw7zw8/LnWfuXMiaW9NZZDvG1Ns9992XdnPlnzfz6ZEqZscHsSAlhCtnR/OHL85l+ZQI3j9QxsbDlVz7+KcsfHg9T3+WP8Q34OwMq4WuJr4LJoUR5udpbyVMRF9KT2DZ5HASQn2HnnkYlk8O53BZo/2G372t8HmJIQT5eHDXspQBAxCsG5fXdhfxk8/PsNdz59IU7lyacsq8MUE+xMw+sw3h1efF8su3DxLu74W/rUX9hfQEyhrauHpOzCm/x45jNUyLDhj2hr+/vsczAF6/dwk/fn0/Nc3t/ONri0i2HWxfmBzKmk15dLT22KeJCA9fP/DB9f7uuySNnfnb7X3p8xJDWLMpl9K6Nr66OInYYG/WZ1eQEu5HaoQ/dyxJ5tkt+dS3dnK4vImHr5912uVHBXrzr3uWYIyxr4vevcy4kBOfwfcumcKXFiYSHehtHzwA8OVFSSxPiyAiwHpuxmUzoogK9GKO7WY2vZ+Fj6d1+OOnR6u46jxr94oAbZ0dzI4Lwsvdjb985XwALq9q5qPscu54ZgfJYX78x+fSWDUreljr60yJo7q609PTTUZGhkPeWymwHogrq2+zB9N48/M3DyCCfZz6YHYfr+X6v2zhq4sT+Z/rhhesw2GMocd2gK9XfUsnc3/5AcbA6q/OZ9WsmNMsYWD1LZ0E+XrYn2cer+V4dQvXzTv19Ja2zm6++Y9d7CqoxdvDjfU/vJAgH49T5judzu4e/vTREe5Ymkx4nyuhDldpfSu+Hu4n1Qzw+w8O8djHR7l5QQIv7yzkmTsW8NSmXH561cyTuiprmztY9sjHnBcfzJrbzrcftD1bIrLLGJM+4Gsa6EpNbN09hvvXZvHVRYkDjiAZaav+uImcskbevW/5SSNQRlvfVvd4UNfSwfJHNtDY3sW06ADeu3/FoPNWN7UT7Ot50sbxbJ0u0LUPXakJzs0iPHbLvDEJc7D2o1vEOjR0LI2nMAfrGd53Lk0GsI9hH0yYv9eIhPlQtA9dKXVGvnPxFC6aFomvp8bHXStSaWzv4uYFCUPPPAa0y0UppSYQ7XJRSikXoIGulFJOQgNdKaWchAa6Uko5CQ10pZRyEhroSinlJDTQlVLKSWigK6WUk3DYiUUiUgmcetPA4QkHqkawnJE0XmvTus7MeK0Lxm9tWteZOdu6kowxA942zGGBfi5EJGOwM6UcbbzWpnWdmfFaF4zf2rSuMzMadWmXi1JKOQkNdKWUchITNdDXOLqA0xivtWldZ2a81gXjtzat68yMeF0Tsg9dKaXUqSZqC10ppVQ/GuhKKeUkJlygi8gqETkkIkdF5AEH1pEgIhtEJFtEDojIfbbpPxeRYhHJsv1c6YDa8kVkn+39M2zTQkXkQxE5Yvs3xAF1Te2zXrJEpEFE7nfEOhORp0WkQkT295k26DoSkf+2fecOicjlY1zX70QkR0T2isjrIhJsm54sIq191tvqMa5r0M9trNbXaWpb26eufBHJsk0fk3V2mnwY3e+YMWbC/ABuQC6QCngCe4AZDqolBphvexwAHAZmAD8H/sPB6ykfCO837bfAA7bHDwCPjIPPsgxIcsQ6A1YA84H9Q60j2+e6B/ACUmzfQbcxrOtzgLvt8SN96kruO58D1teAn9tYrq/Bauv3+u+Bn47lOjtNPozqd2yitdAXAkeNMXnGmA7gZeBaRxRijCk1xmTaHjcC2UCcI2oZpmuB52yPnwOuc1wpAFwC5BpjzvZs4XNijNkE1PSbPNg6uhZ42RjTbow5BhzF+l0ck7qMMR8YY7psT7cB8aPx3mda12mM2foaqjax3ln6i8BLo/X+g9Q0WD6M6ndsogV6HFDY53kR4yBERSQZmAdst036jm33+GlHdG0ABvhARHaJyN22aVHGmFKwftmASAfU1dfNnPxH5uh1BoOvo/H0vfsa8G6f5ykisltENorIcgfUM9DnNp7W13Kg3BhzpM+0MV1n/fJhVL9jEy3QZYBpDh13KSL+wKvA/caYBuBJYBIwFyjFurs31pYaY+YDVwD3isgKB9QwKBHxBK4B/s82aTyss9MZF987EXkQ6AJesE0qBRKNMfOAHwAvikjgGJY02Oc2LtaXzS2c3HAY03U2QD4MOusA0854nU20QC8CEvo8jwdKHFQLIuKB9cN6wRjzGoAxptwY022M6QH+yijuag7GGFNi+7cCeN1WQ7mIxNjqjgEqxrquPq4AMo0x5TA+1pnNYOvI4d87EbkduAr4irF1utp2z6ttj3dh7XdNG6uaTvO5OXx9AYiIO3ADsLZ32lius4HygVH+jk20QN8JTBGRFFsr72bgTUcUYuub+zuQbYx5tM/0mD6zXQ/s7/9/R7kuPxEJ6H2M9YDafqzr6XbbbLcD/x7Luvo5qdXk6HXWx2Dr6E3gZhHxEpEUYAqwY6yKEpFVwH8B1xhjWvpMjxARN9vjVFtdeWNY12Cfm0PXVx+XAjnGmKLeCWO1zgbLB0b7OzbaR3tH4ejxlViPGOcCDzqwjmVYd4n2Alm2nyuBfwD7bNPfBGLGuK5UrEfL9wAHetcREAasB47Y/g110HrzBaqBoD7TxnydYd2glAKdWFtHXz/dOgIetH3nDgFXjHFdR7H2r/Z+z1bb5r3R9hnvATKBq8e4rkE/t7FaX4PVZpv+LPCtfvOOyTo7TT6M6ndMT/1XSiknMdG6XJRSSg1CA10ppZyEBrpSSjkJDXSllHISGuhKKeUkNNCVUspJaKArpZST+P9nv2YCz2UE0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    batch_ix = to_matrix(sample(words, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]  # YOUR CODE HERE\n",
    "    actual_next_tokens = batch_ix[:, 1:]  # YOUR CODE HERE\n",
    "\n",
    "    #     print(predictions_logp.shape, actual_next_tokens.shape)\n",
    "    loss = criterion(\n",
    "        predictions_logp.contiguous().view(-1, num_tokens), actual_next_tokens.contiguous().view(-1)\n",
    "    )\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label=\"loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. \n",
    "All we need is the single rnn step function you have defined in `char_rnn.forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=\" hello\", max_length=MAX_LENGTH, temperature=3):\n",
    "    \"\"\"\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    \"\"\"\n",
    "\n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "\n",
    "    # feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "\n",
    "    # start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logits = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logits / temperature, dim=-1).data.numpy()[0]\n",
    "\n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "\n",
    "    return \"\".join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helloj'ux (d'ytp-t. o ,y(ht lq\n",
      " hello:epeqilhb!qv?(lgiq .s(qjh\n",
      " hellojjdite q t yji  dd-x?.,l:\n",
      " hellodg ''hh.oguvdun' ?mhw ?b:\n",
      " helloywtd .(eg ? krqa (jz,nw?p\n",
      " helloiqglh)moru):rv rrt--u(p?p\n",
      " hellod)m c xzlqi.t (io,,!un gn\n",
      " hello jbln:njsfe-o?ak)rh)'ss' \n",
      " hellopst  ei.d.fg ?nz!h'q)dsv(\n",
      " helloxg;eb tue)gj s lc\n",
      "lx ig).\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(depth):\n",
    "    model = Sequential()\n",
    "\tmodel.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n",
    "\tfor i in range(depth):\n",
    "\t\tmodel.add(LSTM(8, return_sequences=True))\n",
    "\tmodel.add(LSTM(2, return_sequences=True))\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\tif artist + \".rap\" in os.listdir(\".\") and train_mode == False:\n",
    "\t\tmodel.load_weights(str(artist + \".rap\"))\n",
    "\t\tprint(\"loading saved network: \" + str(artist) + \".rap\") \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation with different temperature values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
